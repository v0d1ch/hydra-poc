"use strict";(self.webpackChunkhydra_head_protocol_docs=self.webpackChunkhydra_head_protocol_docs||[]).push([[2209],{3030:function(e){e.exports=JSON.parse('{"blogPosts":[{"id":"1","metadata":{"permalink":"/head-protocol/adr/1","source":"@site/adr/2021-06-05_001-record-architectural-decisions.md","title":"1. Record Architecture Decisions\\n","description":"Status","date":"2021-06-05T00:00:00.000Z","formattedDate":"June 5, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.515,"truncated":false,"authors":[],"frontMatter":{"slug":"1","title":"1. Record Architecture Decisions\\n","authors":[],"tags":["Accepted"]},"nextItem":{"title":"2. Reactive Core\\n","permalink":"/head-protocol/adr/2"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWe are in search for a means to describe our technical architecture.\\n\\nWe are a small team working in a very lean and agile way (XP), so we naturally prefer also light-weight documentation methods which also accomodate change easily.\\n\\n## Decision\\n\\n* We will use _Architecture Decision Records_, as described by Michael Nygard in this [article](http://thinkrelevance.com/blog/2011/11/15/documenting-architecture-decisions).\\n* We will follow the convention of storing those ADRs as Markdown formatted documents stored under `docs/adr` directory, as exemplified in Nat Pryce\'s [adr-tools](https://github.com/npryce/adr-tools). This does not imply we will be using `adr-tools` itself.\\n\\n## Consequences\\n\\nSee Michael Nygard\'s article, linked above."},{"id":"2","metadata":{"permalink":"/head-protocol/adr/2","source":"@site/adr/2021-06-06_002-reactive-core.md","title":"2. Reactive Core\\n","description":"Status","date":"2021-06-06T00:00:00.000Z","formattedDate":"June 6, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.985,"truncated":false,"authors":[],"frontMatter":{"slug":"2","title":"2. Reactive Core\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"1. Record Architecture Decisions\\n","permalink":"/head-protocol/adr/1"},"nextItem":{"title":"3. Asynchronous Duplex Client API","permalink":"/head-protocol/adr/3"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWe are looking for a way of expressing the Hydra Head protocol logic in a Hydra node.\\n\\nThe Hydra Head protocol is defined as a _State machine_ in the paper, whose transitions are inputs that come from different sources which can emit outputs to other instances of the state machine or the mainchain. See the [FC2021](https://iohk.io/en/research/library/papers/hydrafast-isomorphic-state-channels/) paper for details\\n\\nIt should also be easy to review / feed-back to researchers.\\n\\nWe are familiar with React\'s [redux](https://react-redux.js.org/) way of structuring applications, which in turn is inspired by [The Elm Architecture](https://guide.elm-lang.org/architecture/) which itself is a simplification of [Functional Reactive Programming](https://en.wikipedia.org/wiki/Functional_reactive_programming) principles.\\n\\nWe have experienced benefits with _Event Sourcing_ in the domain of persistence in the past\\n\\n## Decision\\n\\nImplements the Hydra Head core logic as a _loop_ that:\\n1. Consumes _input events_ from an event _queue_,\\n2. Applies each _event_ to the current _state_ yielding potentially an _updated state_ and a sequence of _effects_,\\n3. Execute all _effects_.\\n\\n## Consequences\\n\\nThe internal state is only ever changed through _Events_.\\n\\nThe core state machine _transition_ function _is pure_ and reviewing it requires minimal Haskell knowledge.\\n\\nSide-effects are all handled at the level of the `Node`."},{"id":"3","metadata":{"permalink":"/head-protocol/adr/3","source":"@site/adr/2021-06-07_003-asynchronous-duplex-api.md","title":"3. Asynchronous Duplex Client API","description":"Status","date":"2021-06-07T00:00:00.000Z","formattedDate":"June 7, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.845,"truncated":false,"authors":[],"frontMatter":{"slug":"3","title":"3. Asynchronous Duplex Client API","authors":[],"tags":["Accepted"]},"prevItem":{"title":"2. Reactive Core\\n","permalink":"/head-protocol/adr/2"},"nextItem":{"title":"4. Use Handle to model Effects\\n","permalink":"/head-protocol/adr/4"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nThe [_reactive_ nature of the Hydra node](/adr/2) means that\\nclients produce a _stream_ of _inputs_ to a node which in turns issues a stream\\nof _outputs_ representing the outcome of previous inputs or resulting from\\ninteraction with peers in the network.\\n\\nFor example, a client may send a _command_ as _input_, upon which the node might\\ndo something. When that something is finished, a _output_ does indicate that.\\nHowever, there might also be an _output_ emitted to the client when another peer\\ninteracted with \\"our\\" node.\\n\\nQueries, messages by clients which do only fetch information from the node, are\\nnot in scope of this ADR.\\n\\n## Decision\\n\\n* We use a single, full-duplex communication channel per client connected to a Hydra node\\n* This is implemented using a simple [Websocket](https://datatracker.ietf.org/doc/html/rfc6455) with messages corresponding to `Input`s and `Output`s.\\n\\n## Consequences\\n\\n* Clients needing a synchronous API need to implement it on top\\n* Clients can receive _outputs_ decorrelated from any _inputs_ and at any time"},{"id":"4","metadata":{"permalink":"/head-protocol/adr/4","source":"@site/adr/2021-06-08_004-use-handle-to-model-effects.md","title":"4. Use Handle to model Effects\\n","description":"Status","date":"2021-06-08T00:00:00.000Z","formattedDate":"June 8, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.355,"truncated":false,"authors":[],"frontMatter":{"slug":"4","title":"4. Use Handle to model Effects\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"3. Asynchronous Duplex Client API","permalink":"/head-protocol/adr/3"},"nextItem":{"title":"5. Use io-classes\\n","permalink":"/head-protocol/adr/5"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nGiven we are structuring Hydra node as a [reactive core](/adr/2) we need a way to ensure a strict separation of pure and impure (or effectful) code.\\n\\nWe want to be able to test those impure/effectful parts of the code. This requires a means for exchanging the actual implementation for e.g. the function to send messages over a network.\\n\\nAlso we want the ability to swap implementations not only for testing, but also be able\\nto accommodate different usage scenarios, e.g. use a different middleware\\ndepending on peer configuration.\\n\\nIn Haskell there are various common _patterns_ to model effects:\\n  * [Tagless final encoding](http://okmij.org/ftp/tagless-final/index.html) also known as _MTL-style_ although using typeclasses to implement is [not necessary](https://www.foxhound.systems/blog/final-tagless/), whereby Effect(s) are expressed as typeclass(es) which are propagated as constraints\\n  * [Free monads](https://reasonablypolymorphic.com/blog/freer-monads/), or any variant thereof like Eff, freer, extensible-effects, whereby effect(s) are expressed as ADTs which are _interpreted_ in the context of an _Effect stack_\\n  * [Handle](https://jaspervdj.be/posts/2018-03-08-handle-pattern.html) pattern also known as _record-of-functions_ whereby effects are grouped together in a datatype with a single record constructor\\n\\n(These tradeoffs also appear in other functional languages like\\n[F#](https://medium.com/@dogwith1eye/prefer-records-of-functions-to-interfaces-d6413af4d2c3))\\n\\nThere is not one most favored solution though and we all have various\\nexperiences with these techniques.\\n\\n## Decision\\n\\nEffectful components of the Hydra node (our code) will be defined using the _Handle pattern_.\\n\\nThere might be other techniques in use because of libraries used etc.\\n\\n## Consequences\\n\\nFor example, the network component is defined as:\\n  ```hs\\n  newtype Network m = Network\\n    { broadcast :: MonadThrow m => HydraMessage -> m ()\\n    }\\n  ```\\nThere might be multiple `createNetwork :: m (Network m)` functions"},{"id":"5","metadata":{"permalink":"/head-protocol/adr/5","source":"@site/adr/2021-06-09_005-use-io-sim-classes.md","title":"5. Use io-classes\\n","description":"Status","date":"2021-06-09T00:00:00.000Z","formattedDate":"June 9, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.055,"truncated":false,"authors":[],"frontMatter":{"slug":"5","title":"5. Use io-classes\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"4. Use Handle to model Effects\\n","permalink":"/head-protocol/adr/4"},"nextItem":{"title":"6. Network Broadcasts all messages\\n","permalink":"/head-protocol/adr/6"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nAlthough we try to contain the use of IO at the outskirt of the Hydra node using [Handle pattern](/adr/4) and [Reactive core](/adr/2), low-level effects are still needed in various places, notably to define concurrently executing actions, and thus need to be tested\\n\\nTesting asynchronous and concurrent code is notoriously painful\\n\\nThe ouroboros consensus test suite and [hydra-sim](https://github.com/input-output-hk/hydra-sim) simulation have demonstrated the effectiveness of abstracting concurrent primitives through the use of typeclasses (MTL-style pattern) and being able to run these as pure code, harvesting and analysing produced execution traces.\\n\\nThere are other such libraries, e.g. [concurrency](https://hackage.haskell.org/package/concurrency) and [dejafu](https://hackage.haskell.org/package/dejafu), as well as the venerable [exceptions](https://hackage.haskell.org/package/exceptions) (for abstracting exception throwing).\\n\\n## Decision\\n\\nFor all IO effects covered by the library, use functions from typeclasses exposed by [io-classes](https://github.com/input-output-hk/ouroboros-network/tree/e338f2cf8e1078fbda9555dd2b169c6737ef6774/io-classes). As of this writing, this covers:\\n  * All STM operations through `MonadSTM`\\n  * Time and timers through `MonadTime` and `MonadTimer`\\n  * Concurrency through `MonadAsync`, `MonadFork`\\n  * Exceptions through `MonadThrow`, `MonadCatch` and `MonadMask`\\n\\n## Consequences\\n\\nWe can use `io-sim` to evaluate IO-ish functions easily\\n\\nInstantiation to concrete IO is pushed at the outermost layer, eg. in the `Main` or tests.\\n\\nAs some of these functions and typeclasses clash with the\\n[cardano-prelude](https://github.com/input-output-hk/cardano-prelude) we might\\nwant to define a custom prelude (candidate for another ADR)"},{"id":"6","metadata":{"permalink":"/head-protocol/adr/6","source":"@site/adr/2021-06-10_006-network-broadcasts-all-messages.md","title":"6. Network Broadcasts all messages\\n","description":"Status","date":"2021-06-10T00:00:00.000Z","formattedDate":"June 10, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.92,"truncated":false,"authors":[],"frontMatter":{"slug":"6","title":"6. Network Broadcasts all messages\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"5. Use io-classes\\n","permalink":"/head-protocol/adr/5"},"nextItem":{"title":"7. Use with-pattern based component interfaces\\n","permalink":"/head-protocol/adr/7"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nThe simplified Head protocol in the [Hydra\\npaper](https://iohk.io/en/research/library/papers/hydrafast-isomorphic-state-channels/)\\nrequires _unicast_ and _multicast_ messaging between participants. However, this\\ncan be simplified to only _multicast_ by also sending `AckTx` messages to all\\nparticipants and removing the necessity for `ConfTx`.\\n\\nThere is already a battle-tested implementation for _broadcasting_ messages over\\nnetworks with any kind of topology (mesh), namely the\\n[TxSubmission](https://github.com/input-output-hk/ouroboros-network/tree/master/ouroboros-network/src/Ouroboros/Network/TxSubmission)\\nprotocol of `ouroroboros-network`.\\n\\nIf the network connects only to interested peers, _broadcast_ is essentially the\\n_multicast_ required by the protocol. If this is not the case, some addressing\\nscheme is required and _broadcast_ would be a waste of resources.\\n\\n## Decision\\n\\n* All messages emitted by a Hydra node through the Network component are _broadcasted_ to _all_ nodes in the network\\n* This implies the emitter shall itself receive the message\\n\\n## Consequences\\n\\n* The network layer is responsible for ensuring sent messages effectively\\n  reaches all nodes in the network. How this is achieved is left as an\\n  implementation detail, i.e. whether it uses relaying or not.\\n* We need to make sure all Head participants are connected to the same network."},{"id":"7","metadata":{"permalink":"/head-protocol/adr/7","source":"@site/adr/2021-06-11_007-with-pattern-component-interfaces.md","title":"7. Use with-pattern based component interfaces\\n","description":"Status","date":"2021-06-11T00:00:00.000Z","formattedDate":"June 11, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.17,"truncated":false,"authors":[],"frontMatter":{"slug":"7","title":"7. Use with-pattern based component interfaces\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"6. Network Broadcasts all messages\\n","permalink":"/head-protocol/adr/6"},"nextItem":{"title":"8. Custom Prelude\\n","permalink":"/head-protocol/adr/8"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nThe _with pattern_ or _bracket pattern_ is a functional programming idiom, a\\nparticular instance of _Continuation-Passing Style_, whereby one component that\\ncontrols some resource that is consumed by another component of the system, is\\ncreated via a function that takes as argument a function consuming the resource,\\ninstead of returning it. This pattern allows safe reclaiming of resources when\\nthe \\"wrapped\\" action terminates, whether normally or unexpectedly.\\n\\nTODO \\"Tying the knot\\"\\n\\n## Decision\\n\\nWe use this pattern to provide interfaces to all _active components_, which\\nexchange messages with other components of the system. A prototypical signature\\nof such a component could be:\\n\\n  ```hs\\n  type Component m = inmsg -> m ()\\n  type Callback m = outmsg -> m ()\\n\\n  withXXX :: Callback m -> (Component m -> m a) -> m a\\n  ```\\n\\nNote that `withXXX` can also allocate resources in order to provide `Component`\\nor use the `Callback`, e.g. fork threads which invoke `Callback`, but also make\\nsure they are cleaned up.\\n\\n## Consequences\\n\\nComponents can be layered on top of another to provide additional behavior given the same interface. This also similar to \\"decorating\\" in the object-orientation world.\\n\\nIf the `Component` is agnostic about the messages it consumes/produces, it can be defined as a [`Contravariant` functor](https://hackage.haskell.org/package/base-4.15.0.0/docs/Data-Functor-Contravariant.html) and the `Callback` part as a (covariant) `Functor`. This makes it possible to use `map` and `contramap` operations to transform messages."},{"id":"8","metadata":{"permalink":"/head-protocol/adr/8","source":"@site/adr/2021-06-18_008-use-custom-prelude.md","title":"8. Custom Prelude\\n","description":"Status","date":"2021-06-18T00:00:00.000Z","formattedDate":"June 18, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.68,"truncated":false,"authors":[],"frontMatter":{"slug":"8","title":"8. Custom Prelude\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"7. Use with-pattern based component interfaces\\n","permalink":"/head-protocol/adr/7"},"nextItem":{"title":"9. Simplify Logging\\n","permalink":"/head-protocol/adr/9"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nIn a Haskell project, we often get to use and re-use the same libraries and functions. Haskell comes with a default `Prelude` package with the `base` library, which provides a good and sensible starting point. However, the base `Prelude` also comes with a few quirks:\\n\\n- Many commonly used functions or constructors are not exported by default (e.g. `bracket`, `foldM`, `first`, `lift`, `forM`, `when`, `SomeException`, `Set`, `&` ...etc).\\n- Many functions in the base Prelude are partial, like `head` or `read`. \\n- Many functions simply happens in plain `IO`, whereas applications usually try to push IO to the boundary as much as possible (for example, using mtl-style class constraints).\\n- The interface for I/O operations in the base Prelude is `String`, which comes with quite major performance hit and often forces to convert back and forth to `Text` or `ByteString` equivalents.\\n\\nAll-in-all, while it _does the job_, the base `Prelude` may not necessarily be the most _convenient_ prelude for an active project development. \\n\\n## Decision\\n\\nWe\'ll use a custom prelude to help us get more productive and more importantly, to reduce the daily friction of our interactions with the base prelude. While [`relude`](https://hackage.haskell.org/package/relude) makes for a good candidate, we still chose to re-wrap it in a custom `Hydra.Prelude` module to grant us the ability to add or remove a few things specifics to Hydra and Cardano in general. In particular, we will hide from `relude` all the re-exports of the [`stm`](https://hackage.haskell.org/package/stm) library in favor of [`io-classes`](https://github.com/input-output-hk/ouroboros-network/tree/e338f2cf8e1078fbda9555dd2b169c6737ef6774/io-classes) which we already use pervasively and which provides (among other things) most of the same capabilities.\\n\\n## Consequences\\n\\n- Remove uses of \'cardano-prelude\' in favor of a new \'hydra-prelude\' module.\\n- Cleaning up of imports from existing file modules.\\n- Happier feeling day after day from using a developer-friendly prelude.\\n- Stop loosing time in often re-importing the same functions over and over. \\n- Have an explicit point for discouraging / blessing usage of one or the other function, as well as documenting such decisions"},{"id":"9","metadata":{"permalink":"/head-protocol/adr/9","source":"@site/adr/2021-08-19_009-simplify-logging.md","title":"9. Simplify Logging\\n","description":"Status","date":"2021-08-19T00:00:00.000Z","formattedDate":"August 19, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.21,"truncated":false,"authors":[],"frontMatter":{"slug":"9","title":"9. Simplify Logging\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"8. Custom Prelude\\n","permalink":"/head-protocol/adr/8"},"nextItem":{"title":"10. Use Direct Connection to `cardano-node`\\n","permalink":"/head-protocol/adr/10"}},"content":"## Status\\n\\nProposed\\n\\n## Context\\n\\n* Logs are critical to provide _observability_ to Hydra nodes\' operators\\n* Providing the needed components and tools to be able to configure logging and monitoring to each operator\'s liking should not be the responibility of the Hydra node, and requires complex machinery that will need to be maintained and evolved\\n* When a problem occurs in production, if the process is not verbose enough it can be very hard to analyse the problem\\n  * Enabling dynamic changes of verbosity in logs is both complex to implement and comes too late\\n  * Deciding in the code on what\'s the right \\"severity\\" for a log entry leads to dropping important information on _how_ some error occured\\n\\n## Decision\\n\\n_Therefore_\\n\\nHydra node provides a very simplified logging mechanism whereby:\\n* All logs are emitted as JSON-encoded structures providing some metadata (timestamp, threadId) around well-defined data\\n* Each _log entry_ is written to the `hydra-node` process\' _stdout_ port, one line per entry\\n* The definition of the logged items is considered to be part of the public A\u03b3PI of the Hydra node\\n\\n**Note**: Proper redaction of sensitive information contained in log entries should still be handled in the code.\\n\\n## Consequences\\n\\n* The schema of the logged items should be properly documented in a JSON schema, just like we do for client side API\\n* It is the responsibility of the node operator to consume the logs and process them"},{"id":"10","metadata":{"permalink":"/head-protocol/adr/10","source":"@site/adr/2021-10-23_010-use-direct-chain.md","title":"10. Use Direct Connection to `cardano-node`\\n","description":"Status","date":"2021-10-23T00:00:00.000Z","formattedDate":"October 23, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.03,"truncated":false,"authors":[],"frontMatter":{"slug":"10","title":"10. Use Direct Connection to `cardano-node`\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"9. Simplify Logging\\n","permalink":"/head-protocol/adr/9"},"nextItem":{"title":"11. Use cardano-api\\n","permalink":"/head-protocol/adr/11"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* On-Chain Validation is a critical part of the Hydra protocol, it requires both the ability to _submit_ transactions to the _Layer 1_ chain advancing the state of a Head, and _observing_ those transactions as the [Plutus](https://github.com/input-output-hk/plutus) contracts are validated\\n* The [Plutus Application Framework](https://github.com/input-output-hk/plutus-apps) is expected to provide the necessary machinery to allow \\"Smart Contracts\\" applications to interact with the chain but it\'s still under active development and not ready for deployment on-chain\\n* We want to gather feedback as early as possible and deliver a fully functional Hydra Head node for early adopters to test on a \\"real\\" chain (testnet)\\n* Our experiment connecting directly to a Cardano node has been conclusive. We can:\\n  * Connect to a node using local protocols,\\n  * Build and submit Head transactions triggering smart contracts validation, and\\n  * Observe transactions using chain-sync protocol.\\n\\n## Decision\\n\\n_Therefore_\\n\\nFor the time being, until _Plutus Application Framework_ is released, we will implement on-chain interaction of Hydra nodes _directly_, connecting to a Cardano node through a _local socket_.\\n\\n## Consequences\\n\\n* Limit Hydra dependencies to [plutus](https://github.com/input-output-hk/plutus) repository\\n* Remove all PAB-related code as well as off-chain `Contract`s code and related dependencies\\n* An updated architecture diagram:\\n\\n![](../../hydra-node/images/hydra-architecture-direct.jpg)"},{"id":"11","metadata":{"permalink":"/head-protocol/adr/11","source":"@site/adr/2021-11-18_011-use-cardano-api.md","title":"11. Use cardano-api\\n","description":"Status","date":"2021-11-18T00:00:00.000Z","formattedDate":"November 18, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.095,"truncated":false,"authors":[],"frontMatter":{"slug":"11","title":"11. Use cardano-api\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"10. Use Direct Connection to `cardano-node`\\n","permalink":"/head-protocol/adr/10"},"nextItem":{"title":"12. Top-down Test-driven Design\\n","permalink":"/head-protocol/adr/12"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* To implement Hydra Head\'s ledger we have been working with the [ledger-specs](https://github.com/input-output-hk/cardano-ledger-specs) packages which provide a low-level interface to work with transactions and ledgers\\n  * We also use a lightly wrapped ledger-specs API as our interface for Off-chain transaction submission. This introduced some boilerplate in order to align with cardano-api and provide JSON serialisation.\\n* In our initial experiments [connecting directly](/adr/10) to a cardano node we have also been using the ledger API for building transactions for want of some scripts-related features in the cardano-api\\n* cardano-api is expected to be the supported entrypoint for clients to interact with Cardano chain while ledger-specs is reserved for internal use and direct interactions with ledgers\\n* cardano-api now provides all the features we need to run our on-chain validators\\n\\n## Decision\\n\\n_Therefore_\\n\\n* Use cardano-api types and functions instead of ledger-specs in `Hydra.Chain.Direct` component\\n* Use cardano-api types instead of custom ones in `Hydra.Ledger.Cardano` component\\n\\n## Consequences\\n\\n* Removes the boilerplate in `Hydra.Ledger.Cardano` required to map cardano-api types sent by clients to builtin and ledger-specs types\\n* Simplifies the  `Hydra.Chain.Direct` component:\\n  * Replaces custom transaction building in `Tx`\\n  * Replaces custom transaction fees calculation and balancing in `Wallet`\\n  * Replace low-level connection establishment using cardano-api functions connecting to the node (keeping the chain sync subscription)"},{"id":"12","metadata":{"permalink":"/head-protocol/adr/12","source":"@site/adr/2021-11-25_012-top-down-test-driven-design.md","title":"12. Top-down Test-driven Design\\n","description":"Status","date":"2021-11-25T00:00:00.000Z","formattedDate":"November 25, 2021","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.47,"truncated":false,"authors":[],"frontMatter":{"slug":"12","title":"12. Top-down Test-driven Design\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"11. Use cardano-api\\n","permalink":"/head-protocol/adr/11"},"nextItem":{"title":"13. Plutus Contracts Testing Strategy\\n","permalink":"/head-protocol/adr/13"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* [Test-Driven Development](https://en.wikipedia.org/wiki/Test-driven_development) or _Test-Driven Design_ is a technique that helps team promotes simple and loosely coupled design, reduces the amount of code written, increases confidence in delivered software by providing a high level of code coverage by regression tests, and improves development speed through shorter feedback loop\\n* While initially focused on _unit tests_, TDD has evolved over time to include higher-level tests like [Behaviour Driven Development](https://en.wikipedia.org/wiki/Behavior-driven_development) or [Specification by Example](https://en.wikipedia.org/wiki/Specification_by_example), leading to comprehensive strategies like the [Outside-In Diamond TDD](http://tpierrain.blogspot.com/2021/03/outside-in-diamond-tdd-1-style-made.html)\\n* Being a foundational part of scalable applications based on Cardano blockchain, Hydra Head needs to be released early, often, and with high assurance in order to benefit from early adopters\' feedback\\n\\n## Decision\\n\\n_Therefore_\\n\\nWe start as early as possible with _End-to-End_ tests, gradually making them more complex as we develop the various components but starting with something simple (like a system-level but dummy chain and hydra network).\\n\\nWe flesh out other integration tests as needed, when we refine the technological stack used for the various bits and pieces.\\n\\nWe do most of our work in the _Executable Specifications_ layer while we are developing the core domain functions, eg. the Head protocol. The rationale being this is the level at which we can test the most complex behaviours in the fastest and safest possible way as we everything runs without external dependencies or can even run as pure code using io-sim.\\n\\nWe tactically drop to _Unit tests_ level when dealing with the protocol\'s \\"fine prints\\".\\n\\n## Consequences\\n\\n* Development of each \\"feature\\", whether new or change to existing one, should start with a test defined at the highest level possible, but no higher\\n* A detailed presentation of the various testing layers is available in the [wiki](https://github.com/input-output-hk/hydra/wiki/Testing-Strategy)"},{"id":"13","metadata":{"permalink":"/head-protocol/adr/13","source":"@site/adr/2022-01-19_013-contract-testing-strategy.md","title":"13. Plutus Contracts Testing Strategy\\n","description":"Status","date":"2022-01-19T00:00:00.000Z","formattedDate":"January 19, 2022","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":1.26,"truncated":false,"authors":[],"frontMatter":{"slug":"13","title":"13. Plutus Contracts Testing Strategy\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"12. Top-down Test-driven Design\\n","permalink":"/head-protocol/adr/12"},"nextItem":{"title":"14. Token usage in Hydra Scripts\\n","permalink":"/head-protocol/adr/14"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* We are implementing our custom ([Direct](/adr/10)) interaction w/ Cardano blockchain and not using the PAB nor the `Contract` monad to define off-chain contract code\\n* This implies we cannot use the [official](https://github.com/input-output-hk/plutus-apps/blob/main/plutus-contract/src/Plutus/Contract/Test.hs) testing framework for Contracts which relies on `Contract` monad and emulator traces nor the [QuickCheck based framework](https://plutus-apps.readthedocs.io/en/latest/plutus/tutorials/contract-testing.html)\\n* We want to follow our [Test-Driven Development](/adr/12) approach for contracts as this is a critical part of Hydra\\n* On-Chain Validators need not only to be correct and functional, but also secure and hardened against malicious parties\\n\\n## Decision\\n\\n_Therefore_\\n\\n* We test-drive single contracts code using _Mutation-Based Property Testing_\\n* Contracts are tested through the construction of actual _transactions_ and running phase-2 ledger validation process\\n* We start from a \\"healthy\\" transaction, that\'s expected to be correct and stay so\\n* Contract code is initially `const True` function that validates any transaction\\n* We flesh the contract\'s code piecemeal through the introduction of _Mutations_ that turn a healthy transaction into an expectedly invalid one\\n* We gradually build a set of combinators and generators that make it easier to mutate arbitrarily transactions, and combine those mutations\\n\\n## Consequences\\n\\n* We make the contracts\' _Threat model_  explicit through the tests we write, which should help future auditors\' work\\n* We\'ll need an additional layer of tests to exercise the Hydra OCV State Machine through _sequence of transactions_. This could be implemented using [quickcheck-dynamic](https://github.com/input-output-hk/plutus-apps/tree/main/quickcheck-dynamic) library, or other tools that are currently being developed by the Cardano community"},{"id":"14","metadata":{"permalink":"/head-protocol/adr/14","source":"@site/adr/2022-02-14_014-hydra-script-tokens.md","title":"14. Token usage in Hydra Scripts\\n","description":"Status","date":"2022-02-14T00:00:00.000Z","formattedDate":"February 14, 2022","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":2.5,"truncated":false,"authors":[],"frontMatter":{"slug":"14","title":"14. Token usage in Hydra Scripts\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"13. Plutus Contracts Testing Strategy\\n","permalink":"/head-protocol/adr/13"},"nextItem":{"title":"15. Configuration Through an Admin API\\n","permalink":"/head-protocol/adr/15"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* The Hydra on-chain-verification scripts are used to validate Hydra protocol transactions and ensure they are lawful.\\n* At least these three properties need to be enforced:\\n    - Authentication: ensure that only Head participants can, for example, `abort` a Head\\n    - Contract continuity: ensure that a Head was `init`ialized before it can be opened by a `collectCom` tx.\\n    - Completeness: ensure that all Head participants had chance to `commit` funds to a Head.\\n* The Hydra Head paper introduces **participation tokens (PT)** and a **state thread token (ST)** for that matter.\\n* Such tokens (a.k.a native assets) are identified by the `CurrencySymbol`, that is the hash of their `MintingPolicyScript` (a.k.a `PolicyID` in the ledger), and a `ByteString`, the socalled `TokenName` (a.k.a as `AssetName` in the ledger, see [shelley-ma ledger spec](https://hydra.iohk.io/job/Cardano/cardano-ledger-specs/specs.shelley-ma/latest/download-by-type/doc-pdf/shelley-ma#subsection.3.2))\\n* There can be multiple Hydra Heads on a network and a `hydra-node` need to distinguish individual Head instances or even (later) keep track of multiple Heads. Concretely, this means that we need to infer a Head identifier (`HeadId`) from observing each of the Hydra protocol transactions. \\n\\n## Decision\\n\\n* We solve both challenges by defining that ST and PTs **shall use the same** `MintingPolicyScript` and thus have same `CurrencySymbol`\\n* The `MintingPolicyScript` shall be parameterized by `TxOutRef` to yield a unique `CurrencySymbol` per Head\\n(similar to the [`OneShotCurrency`](https://github.com/input-output-hk/plutus/tree/1efbb276ef1a10ca6961d0fd32e6141e9798bd11/plutus-use-cases/src/Plutus/Contracts/Currency.hs) example)\\n* ST and one PT per participant are minted in the `initTx`\\n* The `TokenName` of the ST can be any well-known `ByteString`, e.g. `\\"HydraHeadV1\\"`\\n* The `TokenName` of the PTs needs to be the `PubKeyHash` of the respective participant\\n\\n## Consequences\\n\\n* Heads can be identified by looking for the `ST` in `init`, `collectCom`, `close`, `contest` or `fanout` transactions, or the `PT` in `commit` transactions. In both cases, the `CurrencySymbol == HeadId`\\n* Our scripts become simpler as we only need to check that ST/PT are paid forward, instead of needing to check datums\\n* The datum produced by `commit` txs (and consumed by `collectCom`) is `Just SerializedTxOut`, which is simpler than also keeping the participant which committed in the datum (compare to full life-cycle of [0.3.0](https://github.com/input-output-hk/hydra/tree/0.3.0/docs/images/on-chain-full.jpg)).\\n\\n* The `v_head` script validator does not need to be parameterized, which makes discovering new Heads (and also tracking them for metrics) easier as the address to watch for is common to all Heads (of the same `v_head` version).\\n* The `v_head` script (path) for the abort life-cycle can be implemented already much safer by checking that all PTs are burned on the `abort` transaction (counting inputs in abort life-cycle of [0.3.0](https://github.com/input-output-hk/hydra/tree/0.3.0/docs/images/on-chain-abort.jpg)).\\n* Updated diagrams for the [full](img/on-chain-full.jpg) and [abort](img/on-chain-abort.jpg) on-chain life-cycles of a Hydra Head.\\n\\n## Follow-up questions\\n\\n* What value does the `ST` actually add? We could always look for the `PT` to identify a Head and contract continuity would already be achieved by the `PT`s!\\n* In discussions it turned out to be not clear where the Head\'s `CurrencySymbol` is coming from, and consequently how to identify that an `ST` is indeed an `ST`?"},{"id":"15","metadata":{"permalink":"/head-protocol/adr/15","source":"@site/adr/2022-03-17_015-admin-api.md","title":"15. Configuration Through an Admin API\\n","description":"Status","date":"2022-03-17T00:00:00.000Z","formattedDate":"March 17, 2022","tags":[{"label":"Draft","permalink":"/head-protocol/adr/tags/draft"}],"readingTime":3.105,"truncated":false,"authors":[],"frontMatter":{"slug":"15","title":"15. Configuration Through an Admin API\\n","authors":[],"tags":["Draft"]},"prevItem":{"title":"14. Token usage in Hydra Scripts\\n","permalink":"/head-protocol/adr/14"},"nextItem":{"title":"16. Keep Rejected ADRs\\n","permalink":"/head-protocol/adr/16"}},"content":"## Status\\n\\nDraft\\n\\n## Context\\n\\n* Hydra-node currently requires a whole slew of command-line arguments to configure properly its networking layer: `--peer` to connect to each peer, `--cardano-verification-key` and `--hydra-verification-key` to identify the peer on the L1 and L2 respectively.\\n* This poses significant challenges for operating a _cluster_ of Hydra nodes as one needs to know beforehand everything about the cluster, then pass a large number of arguments to some program or docker-compose file, before any node can be started\\n  * This is a pain that\'s been felt first-hand for benchmarking and testing purpose\\n* Having static network configuration is probably not sustainable in the long run, even if we don\'t add any fancy multihead capabilities to the node, as it would make it significantly harder to have automated creation of Heads.\\n* There\'s been an [attempt](https://github.com/input-output-hk/hydra/pull/222) at providing a file-based network configuration but this was deemed unconvincing\\n* [Hydra paper (sec. 4, p. 13)](https://eprint.iacr.org/2020/299.pdf) explicitly assumes the existence of a _setup_ phase\\n  * This _setup_ is currently left aside, e.g. exchange of keys for setting up multisig and identifying peers. The [hydra-node](https://github.com/input-output-hk/hydra/blob/abailly-iohk/admin-api-adr/hydra-node/exe/hydra-node/Main.hs#L41) executable is statically configured and those things are assumed to be known beforehand\\n\\n## Decision\\n\\n* Hydra-node exposes an _Administrative API_ to enable configuration of the Hydra network using \\"standard\\" tools\\n  * API is exposed as a set of HTTP endpoints on some port, consuming and producing JSON data,\\n  * It is documented as part of the User\'s Guide for Hydra Head\\n* This API provides _commands_ and _queries_ to:\\n  * Add/remove _peers_ providing their address and keys,\\n  * List currently known peers and their connectivity status,\\n  * Start/stop/reset the Hydra network\\n* This API is implemented by a _new component_ accessible through a network port separate from current _Client API_, that _configures_ the `Network` component\\n\\nThe following picture sketches the proposed architectural change:\\n\\n![Architecture change](img/0015-architecture-change.jpg)\\n\\n## Q&A\\n\\n* *Why a REST interface?*\\n  * This API is an interface over a specific _resource_ controlled by the Hydra node, namely its knowledge of other peers with which new _Head_s can be opened. As such a proper REST interface (_not_ RPC-in-disguise) seems to make sense here, rather than stream/event-based [duplex communication channels](/adr/3)\\n  * We can easily extend such an API with WebSockets to provide notifications (e.g. peers connectivity, setup events...)\\n* *Why a separate component?*\\n  * We could imagine extending the existing [APIServer](https://github.com/input-output-hk/hydra/blob/9129c7c013fe2cdc77db048a54981e1ace0843b8/hydra-node/src/Hydra/API/Server.hs) interface with new messages related to this network configuration, however this seems to conflate different responsibilities in a single place: Configuring and managing the Hydra node itself, and configuring, managing, and interacting with the Head itself\\n  * \\"Physical\\" separation of endpoints makes it easier to secure a very sensitive part of the node, namely its administration, e.g by ensuring this can only be accessed through a specific network interface, without relying on application level authentication mechanisms\\n\\n## Consequences\\n\\n* It\'s easy to deploy Hydra nodes with some standard configuration, then dynamically configure them, thus reducing the hassle of defining and configuring the Hydra network\\n* It makes it possible to _reconfigure_ a Hydra node with different peers\\n* The _Client API_ should reflect the state of the network and disable `Init`ing a head if the network layer is not started\\n  * In the long run, it should also have its scope reduced to represent only the possible interactions with a _Head_, moving things related to network connectivity and setup to the Admin API\\n  * In a _Managed Head_ scenario it would even make sense to have another layer of separation between the API to manage the life-cycle of the Head and the API to make transactions within the Head\\n* Operational tools could be built easily on top of the API, for command-line or Web-based configuration"},{"id":"16","metadata":{"permalink":"/head-protocol/adr/16","source":"@site/adr/2022-03-23_016-keep-rejected-adr.md","title":"16. Keep Rejected ADRs\\n","description":"Status","date":"2022-03-23T00:00:00.000Z","formattedDate":"March 23, 2022","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":0.72,"truncated":false,"authors":[],"frontMatter":{"slug":"16","title":"16. Keep Rejected ADRs\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"15. Configuration Through an Admin API\\n","permalink":"/head-protocol/adr/15"},"nextItem":{"title":"17. Use UDP protocol for Hydra networking\\n","permalink":"/head-protocol/adr/17"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\nWe have started using _Architecture Decision Records_ as our primary way to document the most important design decisions we take while developing Hydra Node, and this has proved effective in fostering fruitful discussions about major architecture changes.\\n\\nDuring the course of this project, we have sometimes had debates on various topics leading to rejection of [some ADRs](https://github.com/input-output-hk/hydra/pull/230). It could be the case that  a previously rejected proposal turns out to be interesting, either because the context and situation have changed enough to reevaluate a proposal, or as background for some new proposal.\\n\\n## Decision\\n\\n_therefore_\\n\\n* We will keep rejected _Architecture Decision Records_ alongside accepted and draft ones, in the same location and format\\n* Rejected ADRs _must_ have tag `[Rejected]` set\\n\\n## Consequences\\n\\nOnce attributed a _serial number_ an ADR keeps it \\"forever\\", whether it\'s rejected or accepted"},{"id":"17","metadata":{"permalink":"/head-protocol/adr/17","source":"@site/adr/2022-03-28_017-udp-networking.md","title":"17. Use UDP protocol for Hydra networking\\n","description":"Status","date":"2022-03-28T00:00:00.000Z","formattedDate":"March 28, 2022","tags":[{"label":"Draft","permalink":"/head-protocol/adr/tags/draft"}],"readingTime":1.5,"truncated":false,"authors":[],"frontMatter":{"slug":"17","title":"17. Use UDP protocol for Hydra networking\\n","authors":[],"tags":["Draft"]},"prevItem":{"title":"16. Keep Rejected ADRs\\n","permalink":"/head-protocol/adr/16"},"nextItem":{"title":"18. Single state in Hydra.Node.\\n","permalink":"/head-protocol/adr/18"}},"content":"## Status\\n\\nDraft\\n\\n## Context\\n\\nCurrent Hydra networking layer is based on [Ouroboros network framework](https://github.com/input-output-hk/ouroboros-network/tree/master/ouroboros-network-framework) networking stack which, among other features, provides:\\n1. An abstraction of stream-based duplex communication channels called a [Snocket](https://github.com/input-output-hk/ouroboros-network/blob/6c15a8093bac34091ad96af2b8b0d1f7fe54b732/ouroboros-network-framework/src/Ouroboros/Network/Snocket.hs),\\n2. A Multiplexing connection manager that manages a set of equivalent peers, maintains connectivity, and ensures diffusion of messages to/from all peers,\\n2. Typed protocols for expressing the logic of message exchanges as a form of _state machine_.\\n\\nWhile it\'s been working mostly fine so far, the abstractions and facilities provided by this network layer are not well suited for Hydra Head networking. Some of the questions and shortcomings are discussed in a document on [Networking Requirements](/core-concepts/networking), and as the Hydra Head matures it seems time is ripe for overhauling current network implementation to better suite current and future Hydra Head networks needs.\\n\\n## Decision\\n\\n* Hydra Head nodes communicate by sending messages to other nodes using [UDP](https://en.wikipedia.org/wiki/User_Datagram_Protocol) protocol\\n\\n## Details\\n\\n* _How do nodes know each other?_: This is unspecified by this ADR and left for future work, it is assumed that a Hydra node operator knows the IP:Port address of its peers before opening a Head with them\\n* _Are messages encrypted?_: This should probably be the case in order to ensure Heads\' privacy but is also left for future work\\n* _How are nodes identified?_: At the moment they are identified by their IP:Port pair. As we implement more of the setup process from section 4 of the Hydra Head paper, we should identify nodes by some public key(hash) and resolve the actual IP:Port pair using some other mechanism\\n\\n## Consequences\\n\\n* Node\'s _HeadLogic_ handles lost, duplicates, and out-of-order messages using _retry_ and _timeout_ mechanisms\\n* Messages should carry a unique identifier, eg. source node and index\\n* Protocol, eg. messages format, is documented"},{"id":"18","metadata":{"permalink":"/head-protocol/adr/18","source":"@site/adr/2022-04-13_018-single-state.md","title":"18. Single state in Hydra.Node.\\n","description":"Status","date":"2022-04-13T00:00:00.000Z","formattedDate":"April 13, 2022","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":3.705,"truncated":false,"authors":[],"frontMatter":{"slug":"18","title":"18. Single state in Hydra.Node.\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"17. Use UDP protocol for Hydra networking\\n","permalink":"/head-protocol/adr/17"},"nextItem":{"title":"19. Use of reference scripts\\n","permalink":"/head-protocol/adr/19"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* Currently the `hydra-node` maintains two pieces of state during the life-cycle of a Hydra Head:\\n  1. A `HeadState tx` provided by the `HydraHead tx m` handle interface and part of the `Hydra.Node` module. It provides the basis for the main `hydra-node` business logic in `Hydra.Node.processNextEvent` and `Hydra.HeadLogic.update`\\n  [Creation](https://github.com/input-output-hk/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Node.hs#L256-L257), [Usage](https://github.com/input-output-hk/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Node.hs#L174)\\n  2. `SomeOnChainHeadState` is kept in the `Hydra.Chain.Direct` to keep track of the latest known head state, including notable transaction outputs and information how to spend it (e.g. scripts and datums)\\n  [Code](https://github.com/input-output-hk/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L156-L162), [Usage 1](https://github.com/input-output-hk/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L449), [Usage 2](https://github.com/input-output-hk/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L414), [Usage 3](https://github.com/input-output-hk/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L349-L352)\\n  (There are other unrelated things kept in memory like the event history in the API server or a peer map in the network heartbeat component.)\\n* The interface between the `Hydra.Node` and a `Hydra.Chain` component consists of \\n  - constructing certain Head protocol transactions given a description of it (`PostChainTx tx`):\\n    ```hs\\n    postTx :: MonadThrow m => PostChainTx tx -> m ()\\n    ```\\n  - a callback function when the `Hydra.Chain` component observed a new Head protocol transaction described by `OnChainTx tx`:\\n    ```hs\\n    type ChainCallback tx m = OnChainTx tx -> m ()\\n    ```\\n* Given by the usage sites above, the `Hydra.Chain.Direct` module requires additional info to do both, construct protocol transactions with `postTx` as well as observe potential `OnChainTx` ([here](https://github.com/input-output-hk/hydra/blob/a98e2907c4e425de2736782793383aad63132c14/hydra-node/src/Hydra/Chain/Direct.hs#L333-L336)). Hence we see that, operation of the `Hydra.Chain.Direct` component (and likely any implementing the interface fully) is **inherently stateful**.\\n* We are looking at upcoming features to [handle rollbacks](https://github.com/input-output-hk/hydra/issues/185) and dealing with [persisting the head state](https://github.com/input-output-hk/hydra/issues/187).\\n  - Both could benefit from the idea, that the `HeadState` is just a result of pure `Event` processing (a.k.a event sourcing).\\n  - Right now the `HeadState` kept in `Hydra.Node` alone, is not enough to fully describe the state of the `hydra-node`. Hence it would not be enough to just persist all the `Event`s and replaying them to achieve persistence, nor resetting to some previous `HeadState` in the presence of a rollback.\\n\\n## Decision\\n\\n* We define and keep a \\"blackbox\\" `ChainStateType tx` in the `HeadState tx`\\n  - It shall not be introspectable to the business logic in `HeadLogic`\\n  - It shall contain chain-specific information about the current Hydra Head, which will naturally need to evolve once we have multiple Heads in our feature scope\\n  - For example:\\n  ```hs\\n  data HeadState tx\\n    = IdleState\\n    | InitialState\\n        { chainState :: ChainStateType tx\\n        -- ...\\n        }\\n    | OpenState\\n        { chainState :: ChainStateType tx\\n        -- ...\\n        }\\n    | ClosedState\\n        { chainState :: ChainStateType tx\\n        -- ...\\n        }\\n  ```\\n* We provide the latest `ChainStateType tx` to `postTx`:\\n  ```hs\\n  postTx :: ChainStateType tx -> PostChainTx tx -> m ()\\n  ```\\n* We change the `ChainEvent tx` data type and callback interface of `Chain` to:\\n  ```hs\\n  data ChainEvent tx\\n    = Observation\\n        { observedTx :: OnChainTx tx\\n        , newChainState :: ChainStateType tx\\n        }\\n    | Rollback ChainSlot\\n    | Tick UTCTime\\n\\n  type ChainCallback tx m = (ChainStateType tx -> Maybe (ChainEvent tx)) -> m ()\\n  ```\\nwith the meaning, that invocation of the callback indicates receival of a transaction which is `Maybe` observing a relevant `ChainEvent tx`, where an `Observation` may include a `newChainState`.\\n* We also decide to extend `OnChainEffect` with a `ChainState tx` to explicitly\\n  thread the used `chainState` in the `Hydra.HeadLogic`.\\n\\n## Consequences\\n\\n* We need to change the construction of `Chain` handles and the call sites of `postTx`\\n* We need to extract the state handling (similar to the event queue) out of the `HydraNode` handle and shuffle the main of `hydra-node` a bit to be able to provide the latest `ChainState` to the chain callback as a continuation.\\n* We need to make the `ChainState` serializable (`ToJSON`, `FromJSON`) as it will be part of the `HeadState`.\\n* We can drop the `TVar` of keeping `OnChainHeadState` in the `Hydra.Chain.Direct` module.\\n* We need to update `DirectChainSpec` and `BehaviorSpec` test suites to mock/implement the callback & state handling.\\n* We might be able to simplify the `ChainState tx` to be just a `UTxOType tx` later.\\n* As `OnChainEffect` and `Observation` values will contain a `ChainStateType tx`, traces will automatically include the full `ChainState`, which might be helpful but also possible big. \\n\\n## Alternative\\n\\n* We could extend `PostChainTx` (like `Observation`) with `ChainState` and keep the signatures:\\n```hs\\npostTx :: MonadThrow m => PostChainTx tx -> m ()\\ntype ChainCallback tx m = (ChainState tx -> Maybe (ChainEvent tx) -> m ()\\n```\\n  - Not implemented as it is less clear on the need for a `ChainState` in the signatures."},{"id":"19","metadata":{"permalink":"/head-protocol/adr/19","source":"@site/adr/2022-07-22_019-reference-scripts.md","title":"19. Use of reference scripts\\n","description":"Status","date":"2022-07-22T00:00:00.000Z","formattedDate":"July 22, 2022","tags":[{"label":"Proposed","permalink":"/head-protocol/adr/tags/proposed"}],"readingTime":3.01,"truncated":false,"authors":[],"frontMatter":{"slug":"19","title":"19. Use of reference scripts\\n","authors":[],"tags":["Proposed"]},"prevItem":{"title":"18. Single state in Hydra.Node.\\n","permalink":"/head-protocol/adr/18"},"nextItem":{"title":"20. Handling time\\n","permalink":"/head-protocol/adr/20"}},"content":"## Status\\n\\nProposed\\n\\n## Context\\n\\n* In the desire to make Hydra transactions smaller and cheaper (at the time of writing any abort tx was too big), we want to use the **reference script** and **reference input** features of the upcoming `Babbage` ledger era. See the [babbage ledger spec](https://hydra.iohk.io/build/16861604/download/1/babbage-changes.pdf), [CIP-31](https://github.com/cardano-foundation/CIPs/tree/master/CIP-0031) and [CIP-33](https://github.com/cardano-foundation/CIPs/tree/master/CIP-0033) for details.\\n\\n* With these features we do not need to (re-)include scripts in each transaction.\\n\\n* The CIPs do not specify how reference scripts are to be managed and we can see at least two options:\\n  1. Add them as outputs to the `init` transaction or prior that as part of each Hydra Head instance\\n  2. Post them out-of-band, separate to individual Head instances\\n\\n* Ownership of the outputs holding the scripts is to be considered. If these \\"reference outputs\\" are spent, they cannot be referred to anymore. This would mean all heads referring to them can be denied of service (DoS).\\n\\n* Each head will need to refer to the correct version of the hydra scripts. That is, consistent with the script hashes known to the `hydra-node`.\\n  + This is also related to the problem of managing script versions & updates.\\n  + Right now, the `hydra-node` is compiled against `hydra-plutus` to access compiled script content and hashes.\\n\\n* The general trade-off is: instead of paying ADA fees for scripts adding to the transaction size in _each_ transaction, ADA deposits will need to be put down to have scripts be part of the UTxO set in the ledger _once_.\\n\\n## Decision\\n\\n* Publish outputs holding Hydra scripts out-of-band (option 2), because\\n  + All scripts would not fit into the `init` transaction directly, we would need to post multiple.\\n  + Costs (deposits) would need to be payed for each head instance.\\n\\n* The scripts are stored at outputs addressed to some **unspendable** `v_publish` validator.\\n  + This is to avoid DoS risk and unnecessariy centralization\\n  + We have considered \\"garbage collection\\" by allowing spending these outputs into re-publishing new versions of the script.\\n    - This would make things even more complicated and we decided to not bother about \\"littering the chain\\" right now.\\n\\n* We will publish scripts on release of the `hydra-node`, or more specifically of the `hydra-plutus` package.\\n\\n## Consequences\\n\\n* We need a process and/or tool to publish `hydra-plutus` scripts and need to pay the deposits.\\n  + Any other party could do the same, this does not lead to centralization.\\n\\n* The `hydra-node` would be need to know the `TxIn`s of the \\"right\\" published scripts.\\n  + In the simplest case we would just make this configurable and provide configurations for the various networks after publishing scripts.\\n\\n* If we combine the `v_publish` validator with a \\"tag\\", this allows nodes to \\"discover\\" scripts of a known version \\n  + For example, we could define `HydraHeadV1`, `HydraInitialV1` and `HydraCommitV1` as such tags\\n  + We could parameterize the validator by the tag, yielding unique addresses per tag.\\n  + Alternatively, the \\"tag\\" could be stored in a canonical form as datum on the script outputs. \\n  + In any case, this allows for some checking consistency or easier configuration (not needing to enumerate which `TxIn` is which script)\\n\\n* By also knowing the script hashes the `hydra-node` can verify the integrity of \\"found\\" reference scripts\\n  + This would be possible right now, as they are compiled into the node\\n  + Might be undesirable later for easier system configuration\\n\\n* By making `v_publish` unspendable, we \\"litter\\" the chain. However, any garbage collection scheme would mean potential to DoS again.\\n\\n* Extended diagram for the [abort](img/on-chain-abort-reference-scripts.jpg) on-chain life-cycles of a Hydra Head to include reference scripts."},{"id":"20","metadata":{"permalink":"/head-protocol/adr/20","source":"@site/adr/2022-08-02_020-handling-time.md","title":"20. Handling time\\n","description":"Status","date":"2022-08-02T00:00:00.000Z","formattedDate":"August 2, 2022","tags":[{"label":"Accepted","permalink":"/head-protocol/adr/tags/accepted"}],"readingTime":3.55,"truncated":false,"authors":[],"frontMatter":{"slug":"20","title":"20. Handling time\\n","authors":[],"tags":["Accepted"]},"prevItem":{"title":"19. Use of reference scripts\\n","permalink":"/head-protocol/adr/19"}},"content":"## Status\\n\\nAccepted\\n\\n## Context\\n\\n* The Hydra Head protocol is expected to be isomorphic to the ledger it runs on. That means, it should support the same transaction formats and (if desired) use the same ledger rules as the layer 1.\\n\\n* Cardano is our layer 1 and its consensus layer separates time into discrete steps, where each step is called a `Slot`. The network is expected to evolve strictly monotonically on this time scale and so slot numbers (`SlotNo`) are always increasing.\\n\\n* The Cardano mainnet has a block scheduled every 20 seconds, although it may take longer.\\n  - This is because `slotLength = 1.0` and every 20th slot is \\"active\\" with `f = 0.05`.\\n  - The consensus protocol requires `k` blocks to be produced within `3k/f` slots, where `k = 2160` on mainnet.\\n\\n* Transactions on Cardano may have a validity range with a lower and upper bound given as `SlotNo`.\\n\\n* Wall-clock time can be converted to slots (and back) using an `EraHistory` or `EpochInterpreter` provided by the consensus layer of the cardano node. This is required as the slot lengths could change over time.\\n  - All past points in time since the `SystemStart` can be converted.\\n  - Future points in time can **only** be converted in the \\"safe zone\\", practically being at least `3k/f` slots (TODO: cross check). Refer to chapter 17 *Time* on the [consensus spec](https://hydra.iohk.io/build/16997794/download/1/report.pdf) for more details.\\n\\n* The Hydra Head protocol allows `close` and `contest` transactions only up before a deadline `T_final`, and `fanout` transactions after the deadline.\\n  - In the current implementation the deadline is upper validity of `closed` plus the contestation period.\\n  - We also consider protocol variants which push out the deadline by the contestation period on each `contest`.\\n  - Contestation periods may very well be longer than the stability window of the protocol. For example: 7 days, while the mainnet stability window is more like 36 hours.\\n\\n* We have encountered two problems with handling time in the past\\n  - Trying to convert wall-clock time to slots of the Head protocol deadline led to `PastHorizonException` (when using very low security parameter `k`)\\n  - Trying to `fanout` after the deadline, but before another block has been seen by the L1 ledger led to `OutsideValidityIntervalUTxO`.\\n  \\n* The second problem scenario and solution ideas are roughly visible on this whiteboard:\\n\\n![](img/020-timing-fanout.jpg)\\n\\n## Decision\\n\\n* The head logic uses wall-clock time to track time and only convert to/from slots when constructing/observing transactions in the chain layer.\\n  - This ensures that transactions we post or see on the chain can be converted to/from slots.\\n  - The head logic would use `UTCTime` for points in time and `NominalDiffTime` for durations.\\n  - The chain layer converts these using the `SystemStart` and `EraHistory` into `SlotNo`.\\n\\n* The chain layer informs the logic layer whenever time passed (on the chain) using a new `Tick` event.\\n  - For the direct chain implementation, this is whenever we see a block in the chain sync protocol.\\n  - Per above decision, the `Tick` shall contain a `UTCTime` corresponding to the new \\"now\\" as seen through the block chain.\\n\\n## Consequences\\n\\n* Conversion from `UTCTime -> SlotNo` and vice versa stays local to the chain layer.\\n\\n* The `HeadLogic` can track chain time in its state and condition `ReadyToFanout` upon seeing it pass the deadline.\\n  - Ensures clients only see `ReadyToFanout` when a following `Fanout` would be really possible.\\n  - Makes the `Delay` effect redundant and we can remove it (only delay via reenqueue on the `Wait` outcome)\\n\\n* By introducing `Tick` events, `IOSim` will not be able to detect non-progress (deadlocks).\\n  - This means we cannot rely on early exit of simulations anymore and need to determine meaningful simulation endings instead of `waitUntilTheEndOfTime`.\\n\\n* We get a first, rough notion of time for free in our L2 and can support \\"timed transactions\\" with same resolution as the L1.\\n  - Tracking time in the state makes it trivial to provide it to the ledger when we `applyTransaction`.\\n  - Of course we could extend the fidelity of this feature using the system clock for \\"dead reckoning\\" between blocks. The conversion of wall clock to slot could even be configurable using an L2 `slotLength` analogous to L1 (although we might not want/need this)."}]}')}}]);